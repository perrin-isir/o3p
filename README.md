<div align="center">
<img src="https://raw.githubusercontent.com/perrin-isir/o3p-private/main/o3p/assets/o3p_logo.png" alt="o3p logo"></img>
</div>

[![codestyle](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

**o3p** is a JAX-based library for offline and online off-policy reinforcement learning.

It is currently in BETA VERSION.

<details><summary> <b>Install from source</b> </summary><p>

    git clone https://github.com/perrin-isir/o3p.git


[Jax](https://docs.jax.dev/en/latest/index.html) is in the dependencies, but we recommend to install it beforehand, separately, and verify that it is working well. Please follow instructions at: [https://docs.jax.dev/en/latest/installation.html#installation](https://docs.jax.dev/en/latest/installation.html#installation).

We recommand to create a python environment with [micromamba](https://mamba.readthedocs.io/en/latest/user_guide/micromamba.html),
but any python package manager can be used instead.

    cd o3p

    micromamba create --name o3penv --file environment.yaml

    micromamba activate o3penv

    pip install -e .

<details><summary> <b>How to use it</b> </summary><p>

TODO

<details><summary> <b>Design choices</b> </summary><p>

TODO